{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aknVKhhsSjN_"
      },
      "source": [
        "#**VOLCANOES ERUPTIONS DETECTION NETWORK**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7hP_fCdbC0q"
      },
      "source": [
        "# Google Drive connection to access the dataset\n",
        "When executed it provides a **link to click** in order to get a temporary password (authorization code) to **fill the field**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1v0f-rGtoAv8"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByfiFoaFXCag"
      },
      "source": [
        "# Packages requirements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ohvi1pyVNAU"
      },
      "source": [
        "We need to install some packages before we can start:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuamnWMS5ALT"
      },
      "outputs": [],
      "source": [
        "!rm -rf /content/ai4eo\n",
        "!git clone https://github.com/ESA-PhiLab/ai4eo.git\n",
        "!pip install -e /content/ai4eo/ -r /content/ai4eo/requirements.txt\n",
        "!pip install imgaug"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdKmoCk3suYi"
      },
      "source": [
        "### Standard packages\n",
        "Packages to do numerical computations, to use images, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VuU0h7qZiqNm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "import pandas as pd\n",
        "from skimage.io import imread"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "450CnjrpMZR8"
      },
      "source": [
        "# Volcanoes eruption detection dataset \n",
        "### How the dataset has been created?\n",
        "First of all we found a catalog containing all the information ragarding eruptions happened since 1999. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "5Pztj9jqLyJZ",
        "outputId": "1918f1f5-4896-47d3-c5f6-77ad31d9c99b"
      },
      "outputs": [],
      "source": [
        "catalog = pd.read_csv('/content/drive/My Drive/volcanoes_detection/volcano_eruptions_from_1999_clean.csv')\n",
        "catalog.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fB9YS81nMbDu"
      },
      "source": [
        "The most important information is the **date**, in fact we discarded all the events happened before 2015 (when Sentinel 2 was launched). After that we created a **script that automatically dowloads** Sentinel 2 level 1-C products from **google earth engine platform**. The downloaded images are a cropped version of a \"normal Sen2 image\", in order to focus on volcanos we cut out a 10 by 10 km patch from the original image.  The last preprocessing step made is a **multispectral bands fusion** highlighting **infrared** information. An example of the final product is showed below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        },
        "id": "5nzLWsM9PIXd",
        "outputId": "2b7418dc-9a2f-438e-c636-eeea41c6c7e3"
      },
      "outputs": [],
      "source": [
        "images = {\n",
        "    '/content/drive/My Drive/volcanoes_detection/data_reviewed/validation/eruption/Etna-2018-20170319T095021_20170319T095021_T33SVB.png': 'Eruption',\n",
        "    '/content/drive/My Drive/volcanoes_detection/data_reviewed/validation/eruption/Fournaise, Piton de la-2016-09-11-20160914T063512_20160914T095616_T40KCB.png': 'Eruption',\n",
        "    #'/content/drive/My Drive/volcanoes_detection/data_reviewed/validation/eruption/Barren Island-2018-09-25-20180918T040541_20180918T040745_T46PEU.png': 'Eruption',\n",
        "    #'/content/drive/My Drive/volcanoes_detection/data_reviewed/training/Ubinas-2017-20190624T145731_20190624T150226_T19KBB.png': 'Eruption',\n",
        "    #'/content/drive/My Drive/volcanoes_detection/data_reviewed/training/no_eruption/Fournaise, Piton de la-2019-06-11-20180601T063509_20180601T063505_T40KCB.png': 'No eruption',\n",
        "    #'/content/drive/My Drive/volcanoes_detection/data_reviewed/training/no_eruption/Lat_-17.42105039_Lon_-62.27704286-2019-06-26-20180722T142039_20180722T142403_T20KNF.png': 'No eruption',\n",
        "    '/content/drive/My Drive/volcanoes_detection/data_reviewed/training/no_eruption/NewYork-2019-06-26-20180630T154911_20180630T155933_T18TWL.png': 'No eruption',\n",
        "    '/content/drive/My Drive/volcanoes_detection/data_reviewed/training/no_eruption/SerraGeralDoTocantinsEcologicalStation-2019-06-26-20180520T132241_20180520T132235_T23LLH.png': 'No eruption',\n",
        "    '/content/drive/My Drive/volcanoes_detection/data_reviewed/training/no_eruption/Lat_42.94272116_Lon_46.91295157-2019-06-26-20180626T074731_20180626T075138_T38TPN.png': 'No eruption',\n",
        "}\n",
        "\n",
        "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(10,10))\n",
        "axes = axes.flatten()\n",
        "for i, image in enumerate(images):\n",
        "  axes[i].imshow(imread(image))\n",
        "  axes[i].set_title(images[image])\n",
        "fig.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_drlNa8Lwrd"
      },
      "source": [
        "### Dataset organization\n",
        "\n",
        "- Master folder\n",
        "  - Training folder\n",
        "    - No eruption folder\n",
        "    - Eruption folder\n",
        "  - Validation folder\n",
        "    - No eruption folder\n",
        "    - Eruption folder\n",
        "  - Testing folder\n",
        "    - No eruption folder\n",
        "    - Eruption folder\n",
        "    \n",
        "    \n",
        "### Number of images\n",
        "The dataset contains 1200 images in the training folder and 170 in the validation folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecomWfyKml-c"
      },
      "source": [
        "### **Images resizing and augmentation through Image Generator**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXFjfTlfr9WB"
      },
      "source": [
        "Now we can go on and do **Image Augmentation**.\n",
        "\n",
        "Image Augmentation is a common technique in neural networks to increase the number of images in the dataset by applying particular changes on the available images. Common changes are image flipping and rotating, as well as brightness changing.\n",
        "\n",
        "The Image Generator also helps in terms of **memory usage**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ps8_xkI3NB1i"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "augmentator = ImageDataGenerator(\n",
        "    rotation_range=45,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    zoom_range=[0.3, 1.],\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    fill_mode='reflect',\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1ST9yNIyQVd"
      },
      "source": [
        "Now we can create the input of the neural network by calling this function with these attributes:\n",
        "\n",
        "*   path : the path where the dataset is\n",
        "*   target size : the size\n",
        "*   color mode : how we want to show the images\n",
        "*   classes : the list of classes for our problem\n",
        "*   class mode : the type of classes (in our case it is 'binary' because we have only two classes)\n",
        "*   batch size : the number of images in each batch\n",
        "*   shuffle : set to True to take random images\n",
        "\n",
        "\n",
        "P.S.\n",
        "\n",
        "The image labelling is made by splitting manually the images into different folders (called with the class name)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMlh0DpDxkzr"
      },
      "outputs": [],
      "source": [
        "from ai4eo.preprocessing import ImageLoader\n",
        "import random\n",
        "\n",
        "batch_size = 16\n",
        "train_path = '/content/drive/My Drive/volcanoes_detection/data_reviewed/training/{label}/*.png'\n",
        "val_path = '/content/drive/My Drive/volcanoes_detection/data_reviewed/validation/{label}/*.png'\n",
        "#train_path = '/content/drive/My Drive/volcanoes_detection/training_dataset_color_corr'\n",
        "#val_path = '/content/drive/My Drive/volcanoes_detection/validation_dataset_color_corr'\n",
        "test_path = ' ' \n",
        "\n",
        "# We want to resize the images to 224x224 pixels. They are smaller to reduce \n",
        "# execution time but big enough to preserve features and patterns.\n",
        "target_size = (512,512)\n",
        "\n",
        "def scale_image(image):\n",
        "  # Convert image to float (we cannot perform \n",
        "  # floating operations with unsigned integers)\n",
        "  image = image.astype(float) / 255.\n",
        "  image = np.clip(image, 0., 1.)\n",
        "\n",
        "  # The Neural Network learns better if we zero-center all channels (RGB) and \n",
        "  # set the standard deviation to 1. We calculated these arbitray value as mean\n",
        "  # and standard deviation of the complete training dataset:\n",
        "  image -= np.array([0.44101639, 0.45513914, 0.40195001])\n",
        "  image /= np.array([0.28792392, 0.29775171, 0.29840153])\n",
        "\n",
        "  # We want to make the model more robust, so we randomly add some noise:\n",
        "  if random.random() > 0.8:\n",
        "    image += np.random.uniform(-0.1, 0.1, size=(512, 512))[..., np.newaxis]\n",
        "\n",
        "  return image\n",
        "\n",
        "def scale(image):\n",
        "  image = image.astype(float) / 255.\n",
        "  image = np.clip(image, 0., 1.)\n",
        "  \n",
        "  return image\n",
        "\n",
        "def process_image(image):\n",
        "  image -= np.array([0.44101639, 0.45513914, 0.40195001])\n",
        "  image /= np.array([0.28792392, 0.29775171, 0.29840153])\n",
        "\n",
        "  # We want to make the model more robust, so we randomly add some noise:\n",
        "  if random.random() > 0.8:\n",
        "    image += np.random.uniform(-0.1, 0.1, size=(512, 512))[..., np.newaxis]\n",
        "    \n",
        "  return image\n",
        "\n",
        "\n",
        "train_generator = ImageLoader(\n",
        "    images=train_path, \n",
        "    batch_size=batch_size, \n",
        "    augmentator=augmentator, \n",
        "    balance=True, \n",
        "    label_encoding='binary', \n",
        "    classes=['no_eruption', 'eruption'],\n",
        "    target_size=target_size,\n",
        "    preprocess_input=scale_image,\n",
        "    shuffle=True\n",
        ")\n",
        "val_generator = ImageLoader(\n",
        "    images=val_path, \n",
        "    batch_size=batch_size,\n",
        "    label_encoding='binary',\n",
        "    classes=['no_eruption', 'eruption'],\n",
        "    target_size=target_size,\n",
        "    #preprocess_input=scale_image_noise,\n",
        "    preprocess_input = scale_image,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "test_generator = ImageLoader(\n",
        "    images=val_path, \n",
        "    batch_size=batch_size,\n",
        "    label_encoding='binary',\n",
        "    classes=['no_eruption', 'eruption'],\n",
        "    target_size=target_size,\n",
        "    preprocess_input=scale,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "#batch, _ = train_generator.get_random_samples(350);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wx9KlEK1V4ex"
      },
      "outputs": [],
      "source": [
        "#batch.reshape(-1, 3).std(axis=0), batch.reshape(-1, 3).mean(axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wy-k6dAU9lPg"
      },
      "source": [
        "# Proposed Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O01pni1zXTPj"
      },
      "source": [
        "### Neural network packages\n",
        "You both need to import the **type of model** you want to use (Sequential in our case) and the **layers** that will compose it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y19dLRASXSo_"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Conv2D, Activation, MaxPool2D, Flatten, BatchNormalization, Dropout, Input, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kL1kpQEfbvAQ"
      },
      "source": [
        "### Constants\n",
        "The model needs as **input** a vector with dimensions 224 x 224 x 3: \n",
        "* 224 x 224 is the size in pixels of each image\n",
        "* 3 are the number of channels for an RGB image\n",
        "\n",
        "Other important vector shapes to define are:\n",
        "* the **kernel size** : the size of the filters used for the convolutional layers\n",
        "* the **stride size** : the number of rows and columns with wich the filter moves\n",
        "* the **pool size** : the dimension of the matrices to do the mean for the Pooling layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLjl01_AXv_j"
      },
      "outputs": [],
      "source": [
        "input_shape = (512,512,3)\n",
        "\n",
        "kernel_size = (3,3)\n",
        "stride_size = (1,1)\n",
        "pool_size = (2,2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKPFSR6FunJi"
      },
      "source": [
        "### **Model definition**\n",
        "Here you define how you want your network to be, how many and what type of layers you want to include.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-zWMuyol-sL"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(16, kernel_size, strides=stride_size, padding='same', activation='relu', input_shape=input_shape))\n",
        "model.add(MaxPool2D(pool_size=pool_size, strides=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(32, kernel_size, strides=stride_size, activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=pool_size, strides=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(64, kernel_size, strides=stride_size, activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=pool_size, strides=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(128, kernel_size, strides=stride_size, activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=pool_size, strides=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, kernel_size, strides=stride_size, activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=pool_size, strides=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "model.add(Conv2D(256, kernel_size, strides=stride_size, activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=pool_size, strides=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(512, kernel_size, strides=stride_size, activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=pool_size, strides=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QAGd4Kbuqos"
      },
      "source": [
        "### **Model Compiling**\n",
        "Here you create your neural network and choose the **optimizer**, the **loss function** and the **metrics** to evaluate the performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8HmgIwGYnql"
      },
      "outputs": [],
      "source": [
        "#model.compile(optimizer=RMSprop(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJmvsVL3uM0j"
      },
      "source": [
        "### **Summary**\n",
        "Run to find out how your network looks like and to obtain the number of trainable and not trainable parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8gsxM80LC1A5",
        "outputId": "f0dd1ab2-7313-4c51-d8ae-d63aef674529"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cl-uM82qDpIJ"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXtblC-YXmhM"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score, \\\n",
        "                            classification_report\n",
        "from tensorflow.keras import callbacks as keras_callbacks\n",
        "\n",
        "class AdvancedMetrics(keras_callbacks.Callback):\n",
        "  def __init__(self, data):\n",
        "      super().__init__()\n",
        "      self.data = data\n",
        "  def on_train_begin(self, logs={}):\n",
        "      self.val_f1s = []\n",
        "      self.val_recalls = []\n",
        "      self.val_precisions = []\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    # We need to run the generator twice: once for the input and once for the \n",
        "    # labels. To make sure we are getting the corresponding labels we use \n",
        "    # .reset()\n",
        "    self.data.reset()\n",
        "\n",
        "    # backup the old yield_mode\n",
        "    yield_mode = self.data.yield_mode\n",
        "\n",
        "    self.data.yield_mode = 'inputs'\n",
        "    predictions = self.model.predict_generator(\n",
        "        self.data, use_multiprocessing=True\n",
        "    )\n",
        "    predictions = (predictions > 0.5).astype(int)\n",
        "    self.data.reset()\n",
        "\n",
        "    self.data.yield_mode = 'labels'\n",
        "    targets_generator = iter(self.data)\n",
        "    targets = [\n",
        "        target \n",
        "        for target in next(targets_generator)\n",
        "        for _ in range(len(self.data))\n",
        "    ]\n",
        "    self.data.reset()\n",
        "    self.data.yield_mode = yield_mode\n",
        "\n",
        "    _val_f1 = f1_score(targets, predictions, average='macro')\n",
        "    _val_recall = recall_score(targets, predictions, average='macro')\n",
        "    _val_precision = precision_score(targets, predictions, average='macro')\n",
        "\n",
        "    self.val_f1s.append(_val_f1)\n",
        "    self.val_recalls.append(_val_recall)\n",
        "    self.val_precisions.append(_val_precision)\n",
        "    print(\"\\n val_f1: {:.3f} — val_precision: {:.3f} — val_recall {:.3f}\".format(\n",
        "       _val_f1, _val_precision, _val_recall\n",
        "    ))\n",
        "    print(classification_report(\n",
        "        targets, predictions, target_names=['no_eruption', 'eruption']\n",
        "    ))\n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kudjLsFzYMgg"
      },
      "source": [
        "# Training \n",
        "Now you are ready to train your model! Make sure to set the **number of epochs** you want to use. \n",
        "\n",
        "Other parameters to set are:\n",
        "* the **number of steps per epoch** : the number of training images divided by the batch size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MI8W6kLvx134"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', min_delta=0, patience=50, verbose=0, mode='auto', baseline=None, restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhPd4jHiBcx5"
      },
      "outputs": [],
      "source": [
        "epochs = 200\n",
        "\n",
        "init = time()\n",
        "\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(train_generator),\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=len(val_generator),\n",
        "    epochs=epochs,\n",
        "    #callbacks=[AdvancedMetrics(val_generator)],\n",
        "    #callbacks=[es],\n",
        "    use_multiprocessing=True,\n",
        ")\n",
        "model.save('/content/drive/My Drive/volcanoes_detection/models/big_no_noise.h5')\n",
        "\n",
        "elapsed_time = time() - init"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irx3025UUcj5"
      },
      "source": [
        "## How much time does the model take to be trained for N epochs?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OnozqqneUk0P",
        "outputId": "7d422308-ab6a-440c-b75d-8b9f6c63b381"
      },
      "outputs": [],
      "source": [
        "print('Elapsed time: %f seconds' % (elapsed_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4clD3_nT1mo"
      },
      "source": [
        "# Plot of the model score\n",
        "Here you can see the plots of accuracy and loss both on training and validation datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5tjHTWpTMbM"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(10, 10))\n",
        "\n",
        "axes[0].plot(history.history['acc'])\n",
        "axes[0].plot(history.history['val_acc'])\n",
        "axes[0].legend(['Training Accuracy', 'Validation Accuracy'])\n",
        "axes[0].set_title('Training and Validation Accuracy', fontsize=20)\n",
        "axes[0].set_xlabel('Epochs', fontsize=14)\n",
        "axes[0].set_ylabel('Value', fontsize=14)\n",
        "\n",
        "axes[1].plot(history.history['loss'])\n",
        "axes[1].plot(history.history['val_loss'])\n",
        "axes[1].legend(['Training Loss', 'Validation Loss'])\n",
        "axes[1].set_title('Training and Validation loss', fontsize=20)\n",
        "axes[1].set_xlabel('Epochs', fontsize=14)\n",
        "axes[1].set_ylabel('Value', fontsize=14)\n",
        "\n",
        "fig.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCdOJkiOUCMN"
      },
      "source": [
        "If the model reaches interesting and good results you can use the function below to save it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WjHQGtj3fJ6x"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report, f1_score, precision_score, recall_score\n",
        "def plot_confusion_matrix(\n",
        "       y_true, y_pred, classes, normalize=False,\n",
        "       title=None, cmap=plt.cm.Blues, ax=None):\n",
        "  \"\"\"\n",
        "  This function prints and plots the confusion matrix.\n",
        "  Normalization can be applied by setting normalize=True.\n",
        "  \"\"\"\n",
        "  if not title:\n",
        "    if normalize:\n",
        "        title = 'Normalized confusion matrix'\n",
        "    else:\n",
        "        title = 'Confusion matrix, without normalization'\n",
        "  # Compute confusion matrix\n",
        "  cm = confusion_matrix(y_true, y_pred)\n",
        "  # Only use the labels that appear in the data\n",
        "  #classes = classes[unique_labels(y_true, y_pred)]\n",
        "  if normalize:\n",
        "      cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "  if ax is None:\n",
        "      fig, ax = plt.subplots()\n",
        "  im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "  ax.figure.colorbar(im, ax=ax)\n",
        "  # We want to show all ticks...\n",
        "  ax.set(xticks=np.arange(cm.shape[1]),\n",
        "         yticks=np.arange(cm.shape[0]),\n",
        "         # ... and label them with the respective list entries\n",
        "         xticklabels=classes, yticklabels=classes,\n",
        "         title=title,\n",
        "         ylabel='True label',\n",
        "         xlabel='Predicted label')\n",
        "  # Rotate the tick labels and set their alignment.\n",
        "  plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "            rotation_mode=\"anchor\")\n",
        "  # Loop over data dimensions and create text annotations.\n",
        "  fmt = '.2f' if normalize else 'd'\n",
        "  thresh = cm.max() / 2.\n",
        "  for i in range(cm.shape[0]):\n",
        "       for j in range(cm.shape[1]):\n",
        "           ax.text(j, i, format(cm[i, j], fmt),\n",
        "                   ha=\"center\", va=\"center\",\n",
        "                   color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "  return ax\n",
        "\n",
        "b_predictions, b_targets = None, None\n",
        "for b, batch in enumerate(val_generator):\n",
        "    if b > len(val_generator):\n",
        "        break\n",
        "    inputs, targets = batch\n",
        "    predictions = (model.predict_on_batch(inputs) > 0.5).astype(float)\n",
        "    if b_predictions is None:\n",
        "        b_predictions = predictions\n",
        "        b_targets = targets\n",
        "    else:\n",
        "        b_predictions = np.concatenate([b_predictions, predictions])\n",
        "        b_targets = np.concatenate([b_targets, targets])\n",
        "results = {\n",
        "    'predictions': b_predictions.tolist(),\n",
        "    'targets': b_targets.tolist(),\n",
        "}\n",
        "classes = ['no_eruption', 'eruption']\n",
        "\n",
        "\n",
        "print(classification_report(\n",
        "    b_targets, b_predictions,\n",
        "    target_names=classes\n",
        "))\n",
        "\n",
        "fig, axes = plt.subplots(ncols=2, figsize=(15, 7))\n",
        "plot_confusion_matrix(\n",
        "    results['targets'], results['predictions'], classes,\n",
        "    ax=axes[0]\n",
        ")\n",
        "plot_confusion_matrix(\n",
        "    results['targets'], results['predictions'], classes,\n",
        "    ax=axes[1], normalize=True\n",
        ")\n",
        "fig.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zb-KvHLdVmtr"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "big = load_model('/content/drive/My Drive/volcanoes_detection/models/big_1_good.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "E6KTo1XfkV8M",
        "outputId": "f05f41e6-7944-4caf-f105-7135432e5102"
      },
      "outputs": [],
      "source": [
        "big.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "acDHSij8ngAN"
      },
      "outputs": [],
      "source": [
        "gen = iter(test_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sx41NeslkZVB"
      },
      "outputs": [],
      "source": [
        "x,y = next(gen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 769
        },
        "id": "IbNj5Vzzk518",
        "outputId": "de47e85d-77b0-45eb-faa6-c8a5e50eb6d0"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(10,10))\n",
        "axes = axes.flatten()\n",
        "for i in range(0,9):\n",
        "  axes[i].imshow(np.clip(x[i,...], 0,1))\n",
        "  if y[i] == 0:\n",
        "    axes[i].set_title('No eruption')\n",
        "  else:\n",
        "    axes[i].set_title('Eruption')\n",
        "fig.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "I176MhRe0hrQ",
        "outputId": "daa8df6f-2de2-4c00-8209-13a60b8ae2aa"
      },
      "outputs": [],
      "source": [
        "predicted_classes = np.zeros(16)\n",
        "d = np.zeros((1,512,512,3))\n",
        "\n",
        "for i in range(0, 16):\n",
        "  \n",
        "  img = process_image(x[i,...])\n",
        "  d[0,...] = img\n",
        "  \n",
        "  predicted_classes[i] = big.predict(d)\n",
        "  print('Predicted: ', predicted_classes[i], ' Real: ', y[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLqOC8Keo29T"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "big_model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
