{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aknVKhhsSjN_"
      },
      "source": [
        "#**VOLCANOES ERUPTIONS DETECTION NETWORK**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMCsFZafSjLA"
      },
      "source": [
        "## **WHAT IS A CNN?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxr2a-4cSjH_"
      },
      "source": [
        "A convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, most commonly applied to analyzing visual imagery. The name “convolutional neural network” indicates that the network employs a mathematical operation called **convolution**. Convolution is a specialized kind of linear operation. Convolutional networks are simply neural networks that use convolution in place of general matrix multiplication in at least one of their layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7hP_fCdbC0q"
      },
      "source": [
        "# Google Drive connection to access the dataset\n",
        "When executed it provides a **link to click** in order to get a temporary password (authorization code) to **fill the field**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "1v0f-rGtoAv8",
        "outputId": "0c3747d6-85f3-47f1-aefc-fffa623ab751"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByfiFoaFXCag"
      },
      "source": [
        "# Packages requirements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdKmoCk3suYi"
      },
      "source": [
        "### Standard packages\n",
        "Packages to do numerical computations, to use images, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VuU0h7qZiqNm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuamnWMS5ALT"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/ESA-PhiLab/ai4eo.git\n",
        "!pip install -e /content/ai4eo/\n",
        "!pip install rasterio shapely\n",
        "!git clone https://github.com/atmtools/typhon.git\n",
        "!pip install -e /content/typhon/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cg83UOJwXdQk"
      },
      "source": [
        "###Image preprocessing packages\n",
        "Packages to do images manipulation such as resizing or to do **Image Augmentation**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7X7LygOXgM_"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from skimage.transform import resize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O01pni1zXTPj"
      },
      "source": [
        "### Neural network packages\n",
        "You both need to import the **type of model** you want to use (Sequential in our case) and the **layers** that will compose it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y19dLRASXSo_"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential \n",
        "from tensorflow.keras.layers import Dense, Dropout, Conv2D, Activation, MaxPool2D, Flatten, BatchNormalization, Dropout\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "\n",
        "import tensorflow.keras.backend as K\n",
        "dtype='float16'\n",
        "K.set_floatx(dtype)\n",
        "# default is 1e-7 which is too small for float16.  Without adjusting the epsilon, we will get NaN predictions because of divide by zero problems\n",
        "K.set_epsilon(1e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "450CnjrpMZR8"
      },
      "source": [
        "# Volcanoes eruption detection dataset \n",
        "### How the dataset has been created?\n",
        "First of all we found a catalog containing all the information ragarding eruptions happened since 1999. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "5Pztj9jqLyJZ",
        "outputId": "c63d96d3-bb00-4e82-9645-9c65b1e0357f"
      },
      "outputs": [],
      "source": [
        "catalog = pd.read_csv('/content/drive/My Drive/volcanoes_detection/volcano_eruptions_from_1999_clean.csv')\n",
        "catalog.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fB9YS81nMbDu"
      },
      "source": [
        "The most important information is the **date**, in fact we discarded all the events happened before 2015 (when Sentinel 2 was launched). After that we created a **script that automatically dowloads** Sentinel 2 level 1-C products from **google earth engine platform**. The downloaded images are a cropped version of a \"normal Sen2 image\", in order to focus on volcanos we cut out a 10 by 10 km patch from the original image.  The last preprocessing step made is a **multispectral bands fusion** highlighting **infrared** information. An example of the final product is showed below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        },
        "id": "5nzLWsM9PIXd",
        "outputId": "d46f9128-0a8e-4fb8-c6c2-5f815cfc45ad"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(nrows = 3, ncols = 3, figsize=(10,10))\n",
        "images = []\n",
        "images.append(plt.imread('/content/drive/My Drive/volcanoes_detection/validation_dataset/eruption/Etna-2018-20170319T095021_20170319T095021_T33SVB.png')) \n",
        "images.append(plt.imread('/content/drive/My Drive/volcanoes_detection/validation_dataset/eruption/Fournaise, Piton de la-2016-09-11-20160914T063512_20160914T095616_T40KCB.png'))\n",
        "images.append(plt.imread('/content/drive/My Drive/volcanoes_detection/validation_dataset/eruption/Barren Island-2018-09-25-20180918T040541_20180918T040745_T46PEU.png'))\n",
        "images.append(plt.imread('/content/drive/My Drive/volcanoes_detection/training_dataset/eruption/Ubinas-2017-20190624T145731_20190624T150226_T19KBB.png'))\n",
        "images.append(plt.imread('/content/drive/My Drive/volcanoes_detection/training_dataset/no_eruption/Fournaise, Piton de la-2019-06-11-20180601T063509_20180601T063505_T40KCB.png'))              \n",
        "images.append(plt.imread('/content/drive/My Drive/volcanoes_detection/training_dataset/no_eruption/Lat_-17.42105039_Lon_-62.27704286-2019-06-26-20180722T142039_20180722T142403_T20KNF.png'))              \n",
        "images.append(plt.imread('/content/drive/My Drive/volcanoes_detection/training_dataset/no_eruption/NewYork-2019-06-26-20180630T154911_20180630T155933_T18TWL.png'))  \n",
        "images.append(plt.imread('/content/drive/My Drive/volcanoes_detection/training_dataset/no_eruption/SerraGeralDoTocantinsEcologicalStation-2019-06-26-20180520T132241_20180520T132235_T23LLH.png'))\n",
        "images.append(plt.imread('/content/drive/My Drive/volcanoes_detection/training_dataset/no_eruption/Lat_42.94272116_Lon_46.91295157-2019-06-26-20180626T074731_20180626T075138_T38TPN.png'))              \n",
        "\n",
        "    \n",
        "axes[0,0].imshow(images[0])\n",
        "axes[0,0].set_title('Eruption')\n",
        "axes[0,1].imshow(images[1])\n",
        "axes[0,1].set_title('Eruption')\n",
        "axes[0,2].imshow(images[2])\n",
        "axes[0,2].set_title('Eruption')\n",
        "\n",
        "axes[1,0].imshow(images[3])\n",
        "axes[1,0].set_title('Eruption')\n",
        "axes[1,1].imshow(images[4])\n",
        "axes[1,1].set_title('No eruption')\n",
        "axes[1,2].imshow(images[5])\n",
        "axes[1,2].set_title('No eruption')\n",
        "\n",
        "axes[2,0].imshow(images[6])\n",
        "axes[2,0].set_title('No eruption')\n",
        "axes[2,1].imshow(images[7])\n",
        "axes[2,1].set_title('No eruption')\n",
        "axes[2,2].imshow(images[8])\n",
        "axes[2,2].set_title('No eruption')\n",
        "\n",
        "fig.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_drlNa8Lwrd"
      },
      "source": [
        "### Dataset organization\n",
        "\n",
        "- Master folder\n",
        "  - Training folder\n",
        "    - No eruption folder\n",
        "    - Eruption folder\n",
        "  - Validation folder\n",
        "    - No eruption folder\n",
        "    - Eruption folder\n",
        "  - Testing folder\n",
        "    - No eruption folder\n",
        "    - Eruption folder\n",
        "    \n",
        "    \n",
        "### Number of images\n",
        "The dataset contains 1580 images in the training folder and 128 in the validation folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecomWfyKml-c"
      },
      "source": [
        "### **Images resizing and augmentation through Image Generator**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Op0y5VcROc6V"
      },
      "outputs": [],
      "source": [
        "def scale_image(image):\n",
        "  resized = resize(image, (224,224), anti_aliasing=True, preserve_range=True)\n",
        "  resized = 2.*resized/255.-1.\n",
        "  return resized"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXFjfTlfr9WB"
      },
      "source": [
        "Now the images are 224x224 pixels sized. They are smaller to reduce execution time but big enough to preserve features and patterns.\n",
        "\n",
        "Now we can go on and do **Image Augmentation**.\n",
        "\n",
        "Image Augmentation is a common technique in neural networks to increase the number of images in the dataset by applying particular changes on the available images. Common changes are image flipping and rotating, as well as brightness changing.\n",
        "\n",
        "The Image Generator also helps in terms of **memory usage**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ps8_xkI3NB1i"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "#train_path = '/content/drive/My Drive/volcanoes_detection/training_dataset'\n",
        "#val_path = '/content/drive/My Drive/volcanoes_detection/validation_dataset'\n",
        "train_path = '/content/drive/My Drive/volcanoes_detection/training_dataset_color_corr'\n",
        "val_path = '/content/drive/My Drive/volcanoes_detection/validation_dataset_color_corr'\n",
        "test_path = ' ' \n",
        "target_size = (224,224)\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    #rescale = 2./255,\n",
        "    preprocessing_function = scale_image,\n",
        "    rotation_range = 45,\n",
        "    width_shift_range = 0.2,\n",
        "    height_shift_range = 0.2,\n",
        "    zoom_range = 0.2,\n",
        "    horizontal_flip = True,\n",
        "    vertical_flip = True,\n",
        "    fill_mode = 'reflect'\n",
        "    \n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(\n",
        "    preprocessing_function = scale_image\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1ST9yNIyQVd"
      },
      "source": [
        "Now we can create the input of the neural network by calling this function with these attributes:\n",
        "\n",
        "*   path : the path where the dataset is\n",
        "*   target size : the size\n",
        "*   color mode : how we want to show the images\n",
        "*   classes : the list of classes for our problem\n",
        "*   class mode : the type of classes (in our case it is 'binary' because we have only two classes)\n",
        "*   batch size : the number of images in each batch\n",
        "*   shuffle : set to True to take random images\n",
        "\n",
        "\n",
        "P.S.\n",
        "\n",
        "The image labelling is made by splitting manually the images into different folders (called with the class name)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OV8S59Ii9eeU"
      },
      "outputs": [],
      "source": [
        "ImageLoader?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "iMlh0DpDxkzr",
        "outputId": "88805b92-331b-493e-f0aa-2fcb8ba32801"
      },
      "outputs": [],
      "source": [
        "from ai4eo.preprocessing import ImageLoader\n",
        "\n",
        "train_generator = ImageLoader(\n",
        "    '/content/drive/My Drive/volcanoes_detection/training_dataset_color_corr/{label}/*.png', \n",
        "    batch_size=16, augmentator=datagen, balance=True, label_encoding='binary'\n",
        ")\n",
        "val_generator = ImageLoader(\n",
        "    '/content/drive/My Drive/volcanoes_detection/validation_dataset_color_corr/{label}/*.png', \n",
        "    batch_size=16, augmentator=val_datagen, balance=True, label_encoding='binary'\n",
        ")\n",
        "\n",
        "train_generator_1 = datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size = target_size,\n",
        "    color_mode = 'rgb',\n",
        "    classes = ['no_eruption', 'eruption'],\n",
        "    class_mode = 'binary',\n",
        "    batch_size = batch_size,\n",
        "    shuffle = True\n",
        ")\n",
        "  \n",
        "# val_generator = val_datagen.flow_from_directory(\n",
        "#     val_path,\n",
        "#     target_size = target_size,\n",
        "#     color_mode = 'rgb',\n",
        "#     classes = ['no_eruption', 'eruption'],\n",
        "#     class_mode = 'binary',\n",
        "#     batch_size = batch_size,\n",
        "#     shuffle = True\n",
        "# )\n",
        "\n",
        "# test_generator = test_datagen.flow_from_directory(\n",
        "#     test_path,\n",
        "#     target_size = target_size,\n",
        "#     color_mode = 'rgb',\n",
        "#     classes = ['no_eruption', 'eruption'],\n",
        "#     class_mode = 'binary',\n",
        "#     batch_size = batch_size,\n",
        "#     shuffle = True\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Nw6gswyDDUkm",
        "outputId": "3c328f04-7878-4f16-b072-6c583de1a1e8"
      },
      "outputs": [],
      "source": [
        "b, t = next(iter(train_generator))\n",
        "b.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wy-k6dAU9lPg"
      },
      "source": [
        "# Proposed Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kL1kpQEfbvAQ"
      },
      "source": [
        "### Constants\n",
        "The model needs as **input** a vector with dimensions 224 x 224 x 3: \n",
        "* 224 x 224 is the size in pixels of each image\n",
        "* 3 is the number of channels for an RGB image\n",
        "\n",
        "Other important vector shapes to define are:\n",
        "* the **kernel size** : the size of the filters used for the convolutional layers\n",
        "* the **stride size** : the number of rows and columns with wich the filter moves\n",
        "* the **pool size** : the dimension of the matrices to do the mean for the Pooling layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLjl01_AXv_j"
      },
      "outputs": [],
      "source": [
        "input_shape = (224,224,3)\n",
        "\n",
        "kernel_size = (3,3)\n",
        "stride_size = (1,1)\n",
        "pool_size = (2,2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKPFSR6FunJi"
      },
      "source": [
        "### **Model definition**\n",
        "Here you define how you want your network to be, how many and what type of layers you want to include.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "NA_Bg3oiCKUm",
        "outputId": "b9b4116b-87b8-4059-db11-1e1f19716308"
      },
      "outputs": [],
      "source": [
        "!ls -l '/content/drive/My Drive/volcanoes_detection/data_reviewed/validation/eruption' | wc -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "HK9XBK5NWmAL",
        "outputId": "2565d231-200a-42c7-802a-9037f4039568"
      },
      "outputs": [],
      "source": [
        "!ls -l '/content/drive/My Drive/volcanoes_detection/data_reviewed/validation/no_eruption' | wc -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "7-zWMuyol-sL",
        "outputId": "5f14bc02-7ab1-4482-f2a7-1875f185fd1d"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "# model.add(Conv2D(128, kernel_size, strides=stride_size, padding='same', input_shape=input_shape))\n",
        "# model.add(MaxPool2D(pool_size=pool_size, strides=stride_size, padding='same'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Activation('relu'))\n",
        "\n",
        "# model.add(Conv2D(64, kernel_size, strides=stride_size,input_shape=input_shape ))\n",
        "# model.add(MaxPool2D(pool_size=pool_size, strides=stride_size))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Activation('relu'))\n",
        "# model.add(Conv2D(64, kernel_size, strides=stride_size))\n",
        "# model.add(MaxPool2D(pool_size=pool_size, strides=stride_size))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, kernel_size, strides=stride_size, padding='same', input_shape=input_shape))\n",
        "model.add(MaxPool2D(pool_size=pool_size, strides=stride_size, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "# model.add(Conv2D(64, kernel_size, strides=stride_size, padding='same'))\n",
        "# model.add(MaxPool2D(pool_size=pool_size, strides=stride_size, padding='same'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Activation('relu'))\n",
        "\n",
        "# model.add(Conv2D(32, kernel_size, strides=stride_size))\n",
        "# model.add(MaxPool2D(pool_size=pool_size, strides=stride_size))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Activation('relu'))\n",
        "#model.add(Conv2D(32, kernel_size, strides=stride_size, padding='same'))\n",
        "#model.add(MaxPool2D(pool_size=pool_size, strides=stride_size, padding='same'))\n",
        "#model.add(BatchNormalization())\n",
        "#model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, kernel_size, strides=stride_size, padding='same'))\n",
        "model.add(MaxPool2D(pool_size=pool_size, strides=stride_size, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "# model.add(Conv2D(32, kernel_size, strides=stride_size, padding='same'))\n",
        "# model.add(MaxPool2D(pool_size=pool_size, strides=stride_size, padding='same'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Activation('relu'))\n",
        "\n",
        "# model.add(Conv2D(16, kernel_size, strides=stride_size))\n",
        "# model.add(MaxPool2D(pool_size=pool_size, strides=stride_size))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Activation('relu'))\n",
        "model.add(Conv2D(16, kernel_size, strides=stride_size, padding='same'))\n",
        "model.add(MaxPool2D(pool_size=pool_size, strides=stride_size, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "# model.add(Conv2D(16, kernel_size, strides=stride_size, padding='same'))\n",
        "# model.add(MaxPool2D(pool_size=pool_size, strides=stride_size, padding='same'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Activation('relu'))\n",
        "\n",
        "# model.add(Conv2D(8, kernel_size, strides=stride_size))\n",
        "# model.add(MaxPool2D(pool_size=pool_size, strides=stride_size))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Activation('relu'))\n",
        "model.add(Conv2D(8, kernel_size, strides=stride_size, padding='same'))\n",
        "model.add(MaxPool2D(pool_size=pool_size, strides=stride_size, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QAGd4Kbuqos"
      },
      "source": [
        "### **Model Compiling**\n",
        "Here you create your neural network and choose the **optimizer**, the **loss function** and the **metrics** to evaluate the performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "j8HmgIwGYnql",
        "outputId": "9086fad6-3c83-4cd5-c6aa-8c4e5c032948"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJmvsVL3uM0j"
      },
      "source": [
        "### **Summary**\n",
        "Run to find out how your network looks like and to obtain the number of trainable and not trainable parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "id": "8gsxM80LC1A5",
        "outputId": "79dbd5d7-8318-4d32-8f0a-25e1868f4dbc"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpxCo-aDOoS8"
      },
      "outputs": [],
      "source": [
        "#from tensorflow.keras.models import load_model\n",
        "#big = load_model('/content/drive/My Drive/volcanoes_detection/json_model_score_0.87_color_corr/model_006.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XiHyBYKIXsto"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "from tensorflow.keras import callbacks as keras_callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXtblC-YXmhM"
      },
      "outputs": [],
      "source": [
        "class AdvancedMetrics(keras_callbacks.Callback):\n",
        "  def __init__(self, val_data):\n",
        "      super().__init__()\n",
        "      self.validation_data = val_data\n",
        "  def on_train_begin(self, logs={}):\n",
        "      self.val_f1s = []\n",
        "      self.val_recalls = []\n",
        "      self.val_precisions = []\n",
        "      \n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "      b_predictions, b_targets = None, None\n",
        "      # Go through all validation batches\n",
        "      for b, batch in enumerate(self.validation_data):\n",
        "        if b > len(self.validation_data):\n",
        "          break\n",
        "        inputs, targets = batch\n",
        "        predictions = (self.model.predict_on_batch(inputs) > 0.5).astype(float)\n",
        "        # The first time, there is no exising array to concatenate with\n",
        "        if b_predictions is None:\n",
        "          b_predictions = predictions\n",
        "          b_targets = targets\n",
        "        else:\n",
        "          b_predictions = np.concatenate([b_predictions, predictions])\n",
        "          b_targets = np.concatenate([b_targets, targets])\n",
        "          \n",
        "      _val_f1 = f1_score(b_targets, b_predictions, average='macro')\n",
        "      _val_recall = recall_score(b_targets, b_predictions, average='macro')\n",
        "      _val_precision = precision_score(b_targets, b_predictions, average='macro')\n",
        "      \n",
        "      self.val_f1s.append(_val_f1)\n",
        "      self.val_recalls.append(_val_recall)\n",
        "      self.val_precisions.append(_val_precision)\n",
        "      print(\"\\n val_f1: {:.3f} — val_precision: {:.3f} — val_recall {:.3f}\".format(\n",
        "         _val_f1, _val_precision, _val_recall\n",
        "      ))\n",
        "      return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "KQCdgFG9YxIo",
        "outputId": "0664d05b-15ac-40d7-fcfe-e94515dc0cd7"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.test.is_gpu_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDm70yo9C8XO"
      },
      "outputs": [],
      "source": [
        "b, t = next(iter(train_generator))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "NCuia1imDCm2",
        "outputId": "8d306c1f-d13b-4310-d29d-c430c6f48ab2"
      },
      "outputs": [],
      "source": [
        "b.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kudjLsFzYMgg"
      },
      "source": [
        "# Training \n",
        "Now you are ready to train your model! Make sure to set the **number of epochs** you want to use.\n",
        "\n",
        "Other parameters to set are:\n",
        "* the **number of steps per epoch** : the number of training images divided by the batch size\n",
        "* the **number of validation steps** : the number of validation images divided by the batch size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "xhPd4jHiBcx5",
        "outputId": "cecb3a88-c320-47d7-8266-0921e688e94a"
      },
      "outputs": [],
      "source": [
        "epochs = 120\n",
        "steps_per_epoch = len(train_generator)\n",
        "val_steps = len(val_generator)\n",
        "\n",
        "\n",
        "init = time()\n",
        "\n",
        "history = model.fit_generator(train_generator,\n",
        "                              steps_per_epoch = steps_per_epoch,\n",
        "                              epochs=epochs,\n",
        "                              validation_data=val_generator,\n",
        "                              validation_steps=val_steps,\n",
        "                              callbacks=[AdvancedMetrics(val_generator)],\n",
        "                              use_multiprocessing = True,\n",
        "                              workers = 12\n",
        "                              )\n",
        "\n",
        "elapsed_time = time() - init"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irx3025UUcj5"
      },
      "source": [
        "How much time does the model take to be trained for N epochs?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OnozqqneUk0P"
      },
      "outputs": [],
      "source": [
        "print('Elapsed time: %f seconds' % (elapsed_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4clD3_nT1mo"
      },
      "source": [
        "# Plot of the model score\n",
        "Here you can see the plots of accuracy and loss both on training and validation datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5tjHTWpTMbM"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(10, 10))\n",
        "\n",
        "axes[0].plot(history.history['acc'])\n",
        "axes[0].plot(history.history['val_acc'])\n",
        "axes[0].legend(['Training Accuracy', 'Validation Accuracy'])\n",
        "axes[0].set_title('Training and Validation Accuracy', fontsize=20)\n",
        "axes[0].set_xlabel('Epochs', fontsize=14)\n",
        "axes[0].set_ylabel('Value', fontsize=14)\n",
        "\n",
        "axes[1].plot(history.history['loss'])\n",
        "axes[1].plot(history.history['val_loss'])\n",
        "axes[1].legend(['Training Loss', 'Validation Loss'])\n",
        "axes[1].set_title('Training and Validation loss', fontsize=20)\n",
        "axes[1].set_xlabel('Epochs', fontsize=14)\n",
        "axes[1].set_ylabel('Value', fontsize=14)\n",
        "\n",
        "fig.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCdOJkiOUCMN"
      },
      "source": [
        "If the model reaches interesting and good results you can use the function below to save it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVVNPOLEk61h"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/My Drive/volcanoes_detection/model_9.h5')\n",
        "model.to_json()\n",
        "model.save_weights('/content/drive/My Drive/volcanoes_detection/model_weights_9.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WjHQGtj3fJ6x"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report, f1_score, precision_score, recall_score\n",
        "def plot_confusion_matrix(\n",
        "       y_true, y_pred, classes, normalize=False,\n",
        "       title=None, cmap=plt.cm.Blues, ax=None):\n",
        "  \"\"\"\n",
        "  This function prints and plots the confusion matrix.\n",
        "  Normalization can be applied by setting normalize=True.\n",
        "  \"\"\"\n",
        "  if not title:\n",
        "    if normalize:\n",
        "        title = 'Normalized confusion matrix'\n",
        "    else:\n",
        "        title = 'Confusion matrix, without normalization'\n",
        "  # Compute confusion matrix\n",
        "  cm = confusion_matrix(y_true, y_pred)\n",
        "  # Only use the labels that appear in the data\n",
        "  #classes = classes[unique_labels(y_true, y_pred)]\n",
        "  if normalize:\n",
        "      cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "  if ax is None:\n",
        "      fig, ax = plt.subplots()\n",
        "  im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "  ax.figure.colorbar(im, ax=ax)\n",
        "  # We want to show all ticks...\n",
        "  ax.set(xticks=np.arange(cm.shape[1]),\n",
        "         yticks=np.arange(cm.shape[0]),\n",
        "         # ... and label them with the respective list entries\n",
        "         xticklabels=classes, yticklabels=classes,\n",
        "         title=title,\n",
        "         ylabel='True label',\n",
        "         xlabel='Predicted label')\n",
        "  # Rotate the tick labels and set their alignment.\n",
        "  plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "            rotation_mode=\"anchor\")\n",
        "  # Loop over data dimensions and create text annotations.\n",
        "  fmt = '.2f' if normalize else 'd'\n",
        "  thresh = cm.max() / 2.\n",
        "  for i in range(cm.shape[0]):\n",
        "       for j in range(cm.shape[1]):\n",
        "           ax.text(j, i, format(cm[i, j], fmt),\n",
        "                   ha=\"center\", va=\"center\",\n",
        "                   color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "  return ax\n",
        "\n",
        "b_predictions, b_targets = None, None\n",
        "for b, batch in enumerate(val_generator):\n",
        "    if b > len(val_generator):\n",
        "        break\n",
        "    inputs, targets = batch\n",
        "    predictions = (model.predict_on_batch(inputs) > 0.5).astype(float)\n",
        "    if b_predictions is None:\n",
        "        b_predictions = predictions\n",
        "        b_targets = targets\n",
        "    else:\n",
        "        b_predictions = np.concatenate([b_predictions, predictions])\n",
        "        b_targets = np.concatenate([b_targets, targets])\n",
        "results = {\n",
        "    'predictions': b_predictions.tolist(),\n",
        "    'targets': b_targets.tolist(),\n",
        "}\n",
        "classes = ['no_eruption', 'eruption']\n",
        "\n",
        "\n",
        "print(classification_report(\n",
        "    b_targets, b_predictions,\n",
        "    target_names=classes\n",
        "))\n",
        "\n",
        "fig, axes = plt.subplots(ncols=2, figsize=(15, 7))\n",
        "plot_confusion_matrix(\n",
        "    results['targets'], results['predictions'], classes,\n",
        "    ax=axes[0]\n",
        ")\n",
        "plot_confusion_matrix(\n",
        "    results['targets'], results['predictions'], classes,\n",
        "    ax=axes[1], normalize=True\n",
        ")\n",
        "fig.tight_layout()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "jupyter_notebook_phiweek.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
